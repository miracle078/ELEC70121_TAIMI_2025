{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miracle078/ELEC70121_TAIMI_2025/blob/main/bn2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c09514f",
      "metadata": {
        "id": "4c09514f"
      },
      "source": [
        "# AKI Prediction 48h Onset - Full Implementation\n",
        "Bayesian Neural Network with Clinical Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b21863b",
      "metadata": {
        "id": "0b21863b"
      },
      "source": [
        "## 1. Environment Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e0030d3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0030d3f",
        "outputId": "6bacb174-e0a4-4198-c61f-ca488b789603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.11/dist-packages (1.9.1)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl) (3.4.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl) (0.1.2)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.2)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.23.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.1)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.12.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Collecting numpy<2.5,>=1.23.5 (from scipy)\n",
            "  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mNumPy version: 2.0.2\n"
          ]
        }
      ],
      "source": [
        "# Install core dependencies\n",
        "%pip install torch pyro-ppl shap pandas scikit-learn matplotlib ipywidgets\n",
        "%pip install --upgrade numpy\n",
        "%pip install --upgrade scipy shap\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "57a54e9b",
      "metadata": {
        "id": "57a54e9b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pyro\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
        "from pyro.optim import Adam\n",
        "from pyro.distributions import Normal, Bernoulli\n",
        "from pyro.nn import PyroModule, PyroSample\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
        "                            confusion_matrix, classification_report)\n",
        "from sklearn.calibration import calibration_curve\n",
        "from tqdm.auto import trange\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5f6a8c",
      "metadata": {
        "id": "1e5f6a8c"
      },
      "source": [
        "## 2. Hardware Optimization Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d687beba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d687beba",
        "outputId": "ad9bbea4-2579-45be-c58d-a52ee0ea482e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU\n"
          ]
        }
      ],
      "source": [
        "# Configure device with automatic fallback\n",
        "def configure_hardware():\n",
        "    device = None\n",
        "\n",
        "    # Check CUDA first\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.set_float32_matmul_precision('high')\n",
        "        print(f\"Using NVIDIA GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\n",
        "\n",
        "    # Check Apple Silicon\n",
        "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "        device = torch.device('mps')\n",
        "        print(\"Using Apple Silicon GPU\")\n",
        "\n",
        "    # Check Intel GPUs\n",
        "    elif torch.xpu.is_available():\n",
        "        device = torch.device('xpu')\n",
        "        import intel_extension_for_pytorch as ipex\n",
        "        print(f\"Using Intel GPU: {torch.xpu.get_device_name(0)}\")\n",
        "\n",
        "    # Fallback to CPU\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"Using CPU\")\n",
        "\n",
        "    # Memory optimization\n",
        "    if device.type in ['cuda', 'xpu']:\n",
        "        torch.set_float32_matmul_precision('high')\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "    return device\n",
        "\n",
        "DEVICE = configure_hardware()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e602b8d",
      "metadata": {
        "id": "3e602b8d"
      },
      "source": [
        "## 3. Data Loading & Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "39ac4c9f",
      "metadata": {
        "id": "39ac4c9f"
      },
      "outputs": [],
      "source": [
        "class AKIDataProcessor:\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.labs = ['creatinine', 'bicarbonate', 'chloride', 'glucose', 'magnesium',\n",
        "                     'potassium', 'sodium', 'urea_nitrogen', 'hemoglobin', 'platelet_count',\n",
        "                     'wbc_count', 'lactate', 'paco2', 'ph', 'pao2', 'albumin', 'anion_gap']\n",
        "\n",
        "        self.vitals = ['heart_rate', 'resp_rate', 'temperature', 'spo2',\n",
        "                      'nbp_sys', 'nbp_dias', 'nbp_mean', 'gcs_total']\n",
        "\n",
        "        self.coags = ['inr', 'pt', 'aptt']\n",
        "        self.urine = ['urine_output_ml', 'urine_or', 'urine_pacu']\n",
        "        self.demogs = ['age', 'gender', 'race', 'weight', 'height']\n",
        "\n",
        "        # 'admission_type'\n",
        "\n",
        "    def load_and_preprocess(self):\n",
        "        # Load raw data\n",
        "        df = pd.read_csv(\"/content/drive/MyDrive/AKI-sample-clean.csv\")\n",
        "\n",
        "        # Convert categorical demographics to numeric codes (if they are object types)\n",
        "        for col in ['gender', 'race', 'admission_type']:\n",
        "            if df[col].dtype == object:\n",
        "                df[col] = pd.factorize(df[col])[0]\n",
        "\n",
        "        # Temporal features\n",
        "        df['hour_from_icu'] = df['hour_from_icu'].astype(int)\n",
        "        df['early_icu_period'] = (df['hour_from_icu'] <= 24).astype(int)\n",
        "        df['critical_window'] = ((df['hour_from_icu'] >= 24) & (df['hour_from_icu'] <= 48)).astype(int)\n",
        "\n",
        "        # Creatinine dynamics\n",
        "        df = df.sort_values(['stay_id', 'hour_from_icu'])\n",
        "        df['creatinine_24h_change'] = df.groupby('stay_id')['creatinine'].transform(\n",
        "            lambda x: x.diff().rolling(24, min_periods=1).mean()\n",
        "        )\n",
        "\n",
        "        # KDIGO staging\n",
        "        df['aki_stage'] = 0\n",
        "        df['aki_stage'] = np.where(df['creatinine'] >= 1.5 * df['creatinine'].shift(24), 1, df['aki_stage'])\n",
        "        df['aki_stage'] = np.where(df['creatinine'] >= 2.0 * df['creatinine'].shift(24), 2, df['aki_stage'])\n",
        "        df['aki_stage'] = np.where(df['creatinine'] >= 3.0 * df['creatinine'].shift(24), 3, df['aki_stage'])\n",
        "\n",
        "        # Target definition\n",
        "        df['aki_48h'] = df.groupby('stay_id')['aki_stage'].transform(\n",
        "            lambda x: (x.shift(-48) >= 1).any().astype(int)\n",
        "        )\n",
        "\n",
        "        # Missing indicators for lab, vital, coags, and urine variables\n",
        "        for col in self.labs + self.vitals + self.coags + self.urine:\n",
        "            df[f'is_{col}_missing'] = df[col].isnull().astype(int)\n",
        "\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c350a8",
      "metadata": {
        "id": "43c350a8"
      },
      "source": [
        "## 4. Bayesian Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8ce67a1d",
      "metadata": {
        "id": "8ce67a1d"
      },
      "outputs": [],
      "source": [
        "class BayesianAKINetwork(PyroModule):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        # Informed priors scaled by input dimension\n",
        "        self.fc1 = PyroModule[nn.Linear](input_dim, 64)\n",
        "        self.fc1.weight = PyroSample(\n",
        "            lambda prior: Normal(0, 1/np.sqrt(input_dim)).expand([64, input_dim]).to_event(2))\n",
        "        self.fc1.bias = PyroSample(Normal(0, 0.1).expand([64]).to_event(1))\n",
        "\n",
        "        self.fc2 = PyroModule[nn.Linear](64, 32)\n",
        "        self.fc2.weight = PyroSample(\n",
        "            lambda prior: Normal(0, 1/np.sqrt(64)).expand([32, 64]).to_event(2))\n",
        "        self.fc2.bias = PyroSample(Normal(0, 0.1).expand([32]).to_event(1))\n",
        "\n",
        "        self.out = PyroModule[nn.Linear](32, 1)\n",
        "        self.out.weight = PyroSample(\n",
        "            lambda prior: Normal(0, 1/np.sqrt(32)).expand([1, 32]).to_event(2))\n",
        "        self.out.bias = PyroSample(Normal(0, 0.1).expand([1]).to_event(1))\n",
        "\n",
        "        # Dropout for regularization\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = x.to(DEVICE)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        logits = self.out(x).squeeze()\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        with pyro.plate(\"data\", x.size(0)):\n",
        "            obs = pyro.sample(\"obs\", Bernoulli(probs), obs=y)\n",
        "\n",
        "        return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad8c47e",
      "metadata": {
        "id": "6ad8c47e"
      },
      "source": [
        "## 5. Training Pipeline with GPU Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "37c6e4d1",
      "metadata": {
        "id": "37c6e4d1"
      },
      "outputs": [],
      "source": [
        "class AKITrainer:\n",
        "    def __init__(self, data_path):\n",
        "        self.processor = AKIDataProcessor(data_path)\n",
        "        self.df = self.processor.load_and_preprocess()\n",
        "        self.features = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.imputer = IterativeImputer(max_iter=50, random_state=42)\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        # Feature selection\n",
        "        features = (self.processor.labs + self.processor.vitals +\n",
        "                   self.processor.demogs + self.processor.coags +\n",
        "                   self.processor.urine + ['creatinine_24h_change',\n",
        "                   'early_icu_period', 'critical_window'] +\n",
        "                   [f'is_{col}_missing' for col in\n",
        "                    self.processor.labs + self.processor.vitals +\n",
        "                    self.processor.coags + self.processor.urine])\n",
        "\n",
        "        # Impute missing values\n",
        "        X = self.imputer.fit_transform(self.df[features])\n",
        "        X = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Temporal split\n",
        "        splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "        train_idx, test_idx = next(splitter.split(X, groups=self.df['stay_id']))\n",
        "        val_idx = next(splitter.split(X[train_idx], groups=self.df.iloc[train_idx]['stay_id']))[1]\n",
        "\n",
        "        # Convert to tensors\n",
        "        X_train = torch.tensor(X[train_idx], dtype=torch.float32, device=DEVICE)\n",
        "        y_train = torch.tensor(self.df.iloc[train_idx]['aki_48h'].values,\n",
        "                              dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "        X_val = torch.tensor(X[val_idx], dtype=torch.float32, device=DEVICE)\n",
        "        y_val = torch.tensor(self.df.iloc[val_idx]['aki_48h'].values,\n",
        "                            dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "        X_test = torch.tensor(X[test_idx], dtype=torch.float32, device=DEVICE)\n",
        "        y_test = torch.tensor(self.df.iloc[test_idx]['aki_48h'].values,\n",
        "                             dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "        return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "    def train(self, num_epochs=1000, patience=20):\n",
        "        (X_train, y_train), (X_val, y_val), _ = self.preprocess_data()\n",
        "\n",
        "        # Initialize model\n",
        "        input_dim = X_train.shape[1]\n",
        "        model = BayesianAKINetwork(input_dim).to(DEVICE)\n",
        "        guide = pyro.infer.autoguide.AutoDiagonalNormal(model)\n",
        "\n",
        "        # Class weighting\n",
        "        class_counts = torch.bincount(y_train.long())\n",
        "        class_weights = 1. / class_counts\n",
        "        class_weights = class_weights.to(DEVICE)\n",
        "\n",
        "        # Configure SVI\n",
        "        optimizer = Adam({\"lr\": 0.001, \"betas\": (0.95, 0.999)})\n",
        "        svi = SVI(model, guide, optimizer, loss=self._weighted_loss(class_weights))\n",
        "\n",
        "        # Training state\n",
        "        best_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "        training_loss = []\n",
        "        validation_loss = []\n",
        "\n",
        "        # Mixed precision\n",
        "        scaler = torch.cuda.amp.GradScaler() if DEVICE.type == 'cuda' else None\n",
        "\n",
        "        # Training loop\n",
        "        progress = trange(num_epochs, desc=\"Training\")\n",
        "        for epoch in progress:\n",
        "            # Train step\n",
        "            epoch_loss = 0.0\n",
        "            model.train()\n",
        "            with torch.autocast(device_type=DEVICE.type, enabled=DEVICE.type != 'cpu'):\n",
        "                loss = svi.step(X_train, y_train)\n",
        "\n",
        "            if scaler:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(svi.optim)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                svi.optim.step()\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            with torch.no_grad(), torch.autocast(device_type=DEVICE.type):\n",
        "                val_loss = -guide.log_prob(X_val, y_val).item()\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                progress.close()\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "            training_loss.append(loss)\n",
        "            validation_loss.append(val_loss)\n",
        "            progress.set_postfix({\"Train Loss\": loss, \"Val Loss\": val_loss})\n",
        "\n",
        "        return model, guide, (training_loss, validation_loss)\n",
        "\n",
        "    def _weighted_loss(self, class_weights):\n",
        "        def loss_fn(model, guide, x, y):\n",
        "            probs = model(x)\n",
        "            return -torch.sum(Bernoulli(probs).log_prob(y) * class_weights[y.long()])\n",
        "        return loss_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "375d80e8",
      "metadata": {
        "id": "375d80e8"
      },
      "source": [
        "## 6. Clinical Evaluation & Interpretability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ebf1a83e",
      "metadata": {
        "id": "ebf1a83e"
      },
      "outputs": [],
      "source": [
        "class AKIEvaluator:\n",
        "    def __init__(self, model, guide, test_data):\n",
        "        self.model = model\n",
        "        self.guide = guide\n",
        "        self.X_test, self.y_test = test_data\n",
        "\n",
        "    def predict(self, uncertainty_threshold=0.15):\n",
        "        with torch.no_grad(), torch.autocast(device_type=DEVICE.type):\n",
        "            predictive = Predictive(self.model, guide=self.guide, num_samples=200)\n",
        "            samples = predictive(self.X_test)\n",
        "\n",
        "        probs = samples[\"obs\"].float().mean(dim=0).cpu().numpy()\n",
        "        uncertainty = samples[\"obs\"].float().std(dim=0).cpu().numpy()\n",
        "\n",
        "        # Adaptive deferral\n",
        "        defer_mask = uncertainty > uncertainty_threshold\n",
        "        predictions = np.where(defer_mask, -1, (probs > 0.5).astype(int))\n",
        "\n",
        "        return predictions, probs, uncertainty\n",
        "\n",
        "    def evaluate(self, predictions, probs):\n",
        "        y_true = self.y_test.cpu().numpy()\n",
        "        valid_mask = predictions != -1\n",
        "        y_valid = y_true[valid_mask]\n",
        "        pred_valid = predictions[valid_mask]\n",
        "\n",
        "        metrics = {\n",
        "            \"defer_rate\": 1 - valid_mask.mean(),\n",
        "            \"auc_roc\": roc_auc_score(y_true, probs),\n",
        "            \"auc_prc\": average_precision_score(y_true, probs),\n",
        "            \"sensitivity\": confusion_matrix(y_valid, pred_valid)[1,1] / y_valid.sum(),\n",
        "            \"specificity\": confusion_matrix(y_valid, pred_valid)[0,0] / (len(y_valid)-y_valid.sum()),\n",
        "            \"calibration\": calibration_curve(y_true, probs, n_bins=10)\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def shap_analysis(self, background_samples=100):\n",
        "        background = self.X_test[:background_samples].to(DEVICE)\n",
        "        test_samples = self.X_test[100:105].to(DEVICE)\n",
        "\n",
        "        def model_wrapper(x):\n",
        "            with torch.no_grad(), torch.autocast(device_type=DEVICE.type):\n",
        "                return self.model(x).cpu().numpy()\n",
        "\n",
        "        explainer = shap.DeepExplainer(model_wrapper, background)\n",
        "        shap_values = explainer.shap_values(test_samples)\n",
        "\n",
        "        return shap_values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5b5018",
      "metadata": {
        "id": "6b5b5018"
      },
      "source": [
        "## 7. Execution Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6c15ebc3",
      "metadata": {
        "id": "6c15ebc3"
      },
      "outputs": [],
      "source": [
        "def main(data_path):\n",
        "    # Initialize components\n",
        "    trainer = AKITrainer(data_path)\n",
        "    model, guide, losses = trainer.train()\n",
        "\n",
        "    # Load test data\n",
        "    _, _, test_data = trainer.preprocess_data()\n",
        "\n",
        "    # Evaluate\n",
        "    evaluator = AKIEvaluator(model, guide, test_data)\n",
        "    preds, probs, uncertainty = evaluator.predict()\n",
        "    metrics = evaluator.evaluate(preds, probs)\n",
        "\n",
        "    # Interpretability\n",
        "    shap_values = evaluator.shap_analysis()\n",
        "\n",
        "    return metrics, shap_values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b68e5e",
      "metadata": {
        "id": "d4b68e5e"
      },
      "source": [
        "## 8. Run the Full Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f9f2f00d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "f9f2f00d",
        "outputId": "22d3e093-2f83-459b-af4b-b791e3643b52"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'admission_type'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'admission_type'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-231c28022c37>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Run pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AKI-sample-clean.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Display results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-479888d0a148>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Initialize components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAKITrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-cca14e4cc1fa>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAKIDataProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-7390ee3ac113>\u001b[0m in \u001b[0;36mload_and_preprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Convert categorical demographics to numeric codes (if they are object types)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'race'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'admission_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'admission_type'"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Configure data path\n",
        "    data_path = \"AKI-data.csv\"  # Update this path\n",
        "\n",
        "    # Run pipeline\n",
        "    metrics, shap_values = main(\"/content/drive/MyDrive/AKI-sample-clean.csv\")\n",
        "\n",
        "    # Display results\n",
        "    print(\"Clinical Performance Metrics:\")\n",
        "    print(f\"AUC-ROC: {metrics['auc_roc']:.3f}\")\n",
        "    print(f\"AUC-PRC: {metrics['auc_prc']:.3f}\")\n",
        "    print(f\"Deferral Rate: {metrics['defer_rate']:.1%}\")\n",
        "    print(f\"Sensitivity: {metrics['sensitivity']:.1%}\")\n",
        "    print(f\"Specificity: {metrics['specificity']:.1%}\")\n",
        "\n",
        "    # Plot calibration\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.plot(metrics['calibration'][1], metrics['calibration'][0], 's-')\n",
        "    plt.plot([0,1], [0,1], 'k--')\n",
        "    plt.title(\"Model Calibration\")\n",
        "    plt.xlabel(\"Mean Predicted Probability\")\n",
        "    plt.ylabel(\"Observed Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot SHAP values\n",
        "    shap.summary_plot(shap_values, feature_names=trainer.features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mktDH6z-pqQf"
      },
      "id": "mktDH6z-pqQf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24159928",
      "metadata": {
        "id": "24159928"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Configure data path\n",
        "    data_path = \"/content/drive/MyDrive/AKI-sample-clean.csv\"\n",
        "\n",
        "    # Initialize progress tracking\n",
        "    progress_bar = widgets.IntProgress(\n",
        "        value=0,\n",
        "        min=0,\n",
        "        max=6,\n",
        "        description='Pipeline Progress:',\n",
        "        style={'description_width': 'initial'},\n",
        "        bar_style='info'\n",
        "    )\n",
        "    display(progress_bar)\n",
        "\n",
        "    # 1. Data Loading & Preprocessing\n",
        "    print(\"🔄 [1/6] Loading and preprocessing data...\")\n",
        "    trainer = AKITrainer(data_path)\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = trainer.preprocess_data()\n",
        "    progress_bar.value += 1\n",
        "\n",
        "    # 2. Model Training with Live Updates\n",
        "    print(\"\\n🔥 [2/6] Training model...\")\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    plt.ion()  # Enable interactive mode\n",
        "\n",
        "    def training_callback(epoch, train_loss, val_loss):\n",
        "        ax1.clear()\n",
        "        ax1.plot(train_loss, label='Training Loss')\n",
        "        ax1.plot(val_loss, label='Validation Loss')\n",
        "        ax1.set_title(\"Loss Trajectory\")\n",
        "        ax1.legend()\n",
        "\n",
        "        ax2.clear()\n",
        "        ax2.plot(np.log10(train_loss), label='Log Training Loss')\n",
        "        ax2.set_title(\"Log-Scale Loss\")\n",
        "        ax2.legend()\n",
        "\n",
        "        plt.pause(0.01)\n",
        "\n",
        "    model, guide, (train_loss, val_loss) = trainer.train(callback=training_callback)\n",
        "    progress_bar.value += 1\n",
        "    plt.ioff()\n",
        "\n",
        "    # 3. Model Evaluation\n",
        "    print(\"\\n📊 [3/6] Evaluating model performance...\")\n",
        "    evaluator = AKIEvaluator(model, guide, (X_test, y_test))\n",
        "    preds, probs, uncertainty = evaluator.predict()\n",
        "    progress_bar.value += 1\n",
        "\n",
        "    # 4. Generate Metrics with Enhanced Display\n",
        "    print(\"\\n📈 [4/6] Calculating clinical metrics...\")\n",
        "    metrics = evaluator.evaluate(preds, probs)\n",
        "\n",
        "    # Display metrics table\n",
        "    from IPython.display import HTML\n",
        "    metrics_html = f\"\"\"\n",
        "    <style>\n",
        "    .metrics-table {{background: #f8f9fa; padding: 15px; border-radius: 10px;}}\n",
        "    .metric-value {{color: #2c3e50; font-weight: bold;}}\n",
        "    </style>\n",
        "    <div class='metrics-table'>\n",
        "        <h3>Clinical Performance Report</h3>\n",
        "        <p>✅ AUC-ROC: <span class='metric-value'>{metrics['auc_roc']:.3f}</span></p>\n",
        "        <p>📉 AUC-PRC: <span class='metric-value'>{metrics['auc_prc']:.3f}</span></p>\n",
        "        <p>⏸️ Deferral Rate: <span class='metric-value'>{metrics['defer_rate']:.1%}</span></p>\n",
        "        <p>🎯 Sensitivity: <span class='metric-value'>{metrics['sensitivity']:.1%}</span></p>\n",
        "        <p>🛡️ Specificity: <span class='metric-value'>{metrics['specificity']:.1%}</span></p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(metrics_html))\n",
        "    progress_bar.value += 1\n",
        "\n",
        "    # 5. Visualizations\n",
        "    print(\"\\n🎨 [5/6] Generating visualizations...\")\n",
        "\n",
        "    # Calibration Plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(metrics['calibration'][1], metrics['calibration'][0], 's-', color='#3498db')\n",
        "    plt.plot([0,1], [0,1], 'k--', linewidth=1)\n",
        "    plt.title(\"Model Calibration\", fontsize=12)\n",
        "    plt.xlabel(\"Predicted Probability\", fontsize=10)\n",
        "    plt.ylabel(\"Actual Frequency\", fontsize=10)\n",
        "    plt.grid(alpha=0.2)\n",
        "\n",
        "    # SHAP Summary Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    shap.summary_plot(shap_values, feature_names=trainer.features, plot_type='bar',\n",
        "                     color='#e74c3c', show=False)\n",
        "    plt.title(\"Feature Importance (SHAP Values)\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    progress_bar.value += 1\n",
        "\n",
        "    # 6. Final Output\n",
        "    print(\"\\n✅ [6/6] Pipeline complete!\")\n",
        "    progress_bar.bar_style = 'success'\n",
        "\n",
        "    # Show all plots\n",
        "    plt.show()\n",
        "\n",
        "    # Add interactive controls\n",
        "    print(\"\\n🔧 Additional Controls:\")\n",
        "    uncertainty_slider = widgets.FloatSlider(\n",
        "        value=0.15,\n",
        "        min=0.05,\n",
        "        max=0.5,\n",
        "        step=0.05,\n",
        "        description='Uncertainty Threshold:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    def update_threshold(change):\n",
        "        new_preds = evaluator.predict(change.new)\n",
        "        new_metrics = evaluator.evaluate(new_preds, probs)\n",
        "        print(f\"\\nUpdated Metrics (Threshold={change.new:.2f}):\")\n",
        "        print(f\"Sensitivity: {new_metrics['sensitivity']:.1%}\")\n",
        "        print(f\"Specificity: {new_metrics['specificity']:.1%}\")\n",
        "\n",
        "    uncertainty_slider.observe(update_threshold, names='value')\n",
        "    display(uncertainty_slider)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e2bbf10",
      "metadata": {
        "id": "4e2bbf10"
      },
      "source": [
        "## 9. Save Notebook State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40f0d86c",
      "metadata": {
        "id": "40f0d86c"
      },
      "outputs": [],
      "source": [
        "# Save complete notebook\n",
        "from IPython.display import Javascript\n",
        "from google.colab import files\n",
        "\n",
        "def save_notebook():\n",
        "    display(Javascript('''\n",
        "    require([\"base/js/namespace\"], function(IPython) {\n",
        "        IPython.notebook.save_checkpoint();\n",
        "    });\n",
        "    '''))\n",
        "    !jupyter nbconvert --to notebook /content/bn2.ipynb\n",
        "    files.download(\"/content/aki_prediction_full.ipynb\")\n",
        "\n",
        "# Uncomment to save\n",
        "# save_notebook()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}